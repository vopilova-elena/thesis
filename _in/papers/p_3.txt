Челябинский физико-математический журнал. 2016. Т. 1, вып. 2. С. 24–36.

УДК 519.856

ГЕНЕТИЧЕСКИЙ АЛГОРИТМ С ДИНАМИЧЕСКИМ
РАСПРЕДЕЛЕНИЕМ ВЕРОЯТНОСТЕЙ ВЫБОРА
ГЕНЕТИЧЕСКИХ ОПЕРАТОРОВ ДЛЯ РЕШЕНИЯ ЗАДАЧ
С ЦЕЛОЧИСЛЕННЫМ КОДИРОВАНИЕМ ГЕНОВ

Ю. О. Кашкарева
Челябинский государственный университет, Челябинск, Россия
kashkareva.julija@gmail.com

     Разработаны и протестированы два генетических алгоритма построения суперстроки
     для произвольного бинарного файла. Они основаны на адаптивном подборе исполь-
     зуемого набора генетических операторов.

     Kлючевые слова: построение суперстроки, генетические алгоритмы, задача коммиво-
яжёра.


Введение
   Классические генетические алгоритмы (ГА) работают с хромосомами в виде
битовых строк, которые можно разорвать в произвольном месте, скрестить и по-
лучить допустимое решение. Большинство модификаций генетических алгоритмов
так же оперируют битовыми строками. В частности, классические функции для
тестирования эффективности ГА, такие как функции Растригина или Де Джонга,
предполагают кодирование решений для поиска оптимума в виде бинарной строки.
   Однако существует класс задач, для которых представление решений в ука-
занном виде неэффективно или невозможно. К таким задачам, в частности, от-
носится задача коммивояжёра (ЗК). Одним из методов решения ЗК является ко-
дирование потенциальных решений с помощью последовательности целых чисел,
указывающей порядок обхода графа. Хромосома для такого способа кодирования
представляется в виде массива целых чисел, а каждое число представляет из себя
отдельный ген, который наследуется потомком целиком. При таком способе коди-
рования хромосом, в свою очередь, меняются генетические операторы (ГО), такие
как скрещивание и мутация, в них появляется понятие «ген».
   В своей работе мы изучали применение динамического генетического алгорит-
ма для сжатия и обфускации файлов с помощью решения задачи приближённого
поиска кратчайшей суперстроки (Shortest Common Superstring, SCS), в конечном
счёте сводящегося к решению асимметричной задачи коммивояжёра (Asymmetric
Traveling Salesman Problem, ATSP).

1. Задача поиска кратчайшей суперстроки
    Пусть даны строки x = x1 . . . xn и y = y1 . . . ym . Строка y называется подстрокой
x, если существует i ∈ [0, n − m], такое, что yj = xi+j , 1 ≤ j ≤ m. В этом случае x
является суперстрокой для y. Задача поиска кратчайшей суперстроки заключается
в следующем: дано множество из N строк S = [s1 . . . sN ] над конечным алфавитом
     Генетический алгоритм с динамическим распределением вероятностей выбора...   25

Σ, требуется найти кратчайшую суперстроку s, которая содержит каждую строку
si как подстроку.
    В известных нам работах всегда предполагалось, что исходное разбиение на
подстроки задано заранее и не является частью алгоритма построения суперстроки.
Улучшения в алгоритме поиска суперстроки были связаны именно с определёнными
характеристиками исходных подстрок.
    Мы предположили, что следует изучить возможность получения оптимального
разбиения на подстроки. При этом мы предположили, что чем на большее число
подстрок мы разобьём исходный текст и чем меньшей длины они будут, тем более
короткую суперстроку мы сможем гипотетически получить на их основе, потому
что добиться совпадения коротких подстрок проще, нежели длинных. Так, при под-
строках длиной в один символ суперстрока совпадёт по длине с алфавитом. Однако
разбиение исходного текста на слишком мелкие фрагменты приводит к усложнению
вычисления непосредственно SCS, так как сложность задачи определяется именно
количеством подстрок. Так же растут накладные расходы на восстановление ис-
ходной последовательности подстрок. Очевидно, что параметры разбиения будут
сильно зависеть от исходного файла. Таким образом, мы имеем задачу, для ко-
торой известен алгоритм проверки конкретного решения, однако затруднён поиск
всех возможных решений. Для таких задач хорошо подходят эвристические алго-
ритмы, в частности ГА.
    На производительность ГА и качество найденных им решений существенно вли-
яют параметры работы алгоритма и набор использованных генетических опера-
торов [1]. Поскольку разрабатываемый нами алгоритм не является типовым, то
требуется установить, какие генетические операторы будут давать наилучшие ре-
зультаты. При этом поскольку мы будем получать вероятностное решение при по-
строении разбиения и по нему строить суперстроку, то важно также, чтобы эти
алгоритмы хорошо работали вместе.
    В статье Ю. А. Бюргера [2] предложена идея динамической самоорганизации
параметров ГА. На основе этой идеи некоторые авторы разработали алгоритмы для
решения разнообразных задач. В частности, в работе Ю. Ю. Петрова [3] создан ГА
с регуляцией вероятностей для решения задачи упаковки в контейнеры, а в работе
А. С. Мясникова [4] — ГА с динамическим распределением вероятностей выбора
генетических операторов с оптимизацией по времени работы алгоритма. В данных
работах алгоритм применялся для ГО с классическим кодированием хромосом в
виде битовых строк. При эмпирической проверке разработанные алгоритмы давали
положительные результаты.
    Указанные алгоритмы обладают рядом достоинств по сравнению с классически-
ми алгоритмами. В первую очередь данные алгоритмы могут быть непосредственно
применены к любой задаче, и в ходе их работы произойдёт настройка выбора ГО,
дающих наилучшее решение для задачи с заданными параметрами и указанными
начальными данными. Во-вторых, в ходе работы данных алгоритмов можно со-
брать статистику об использовании ГО и затем применить схему простого ГА с
указанными генетическими операторами.
    На базе указанных алгоритмов нами были разработаны две собственные версии
ГА с динамическим распределением вероятностей выбора генетических операторов
(далее — ГА с ДРВ): одна на базе простого ГА (далее ПГА), другая — по аналогии
с алгоритмом, описанным в [4], однако без оптимизации по времени.
    После того как мы некоторым образом определим разбиение на подстроки ис-
ходного файла, мы можем приступить к непосредственному поиску точного и при-
26                              Ю. О. Кашкарева

ближённого решения задачи SCS.
    Поиск SCS — это NP-полная задача [5]. В [6] показано, что данная задача от-
носится к классу MAX-SNP и отсутствует полиномиальный алгоритм, который
позволял бы найти решение для задачи SCS, отличающееся от оптимального на
произвольную, но заранее заданную константу. Задача поиска кратчайшей строки
сводится к асимметричной задаче коммивояжёра (ATSP), и при числе подстрок,
равном N , точное решение может быть найдено за время 2N с использованием по-
линомиальной памяти [7]. Таким образом, точное решение данной задачи может
быть найдено только при небольшом числе подстрок. Обычно для поиска точного
решения применяют алгоритм Литтла [8].
    В случае большей размерности задачи ищут её приближённое решение с по-
мощью аппроксимационных алгоритмов, имеющих полиномиальное время работы,
и эвристических алгоритмов. Лучший известный полиномиальный алгоритм SCS
имеет фактор приближения 2.5 [9] и основывается на сведении SCS к ATSP, после
чего выполняется построение циклического покрытия минимальной длины. Дан-
ный алгоритм достаточно сложен и, согласно проанализированным источникам, не
используется на практике. Самый известный и наиболее широко распространён-
ный полиномиальный алгоритм решения получил название жадного (GREEDY) и
используется для нахождения решений с фактором приближения 4.
    Эвристические, в частности генетические, алгоритмы работают гораздо дольше,
нежели аппроксимационные полиномиальные, однако дают результат быстрее, чем
алгоритмы точного решения задачи, и получаемая ими суперстрока может быть
существенно короче.
    В известных нам работах, описывающих использование ГА для решения задачи
поиска SCS, применялись ПГА, а также некоторые его адаптивные улучшения, од-
нако не обосновывался выбор определённых ГО. Даже в распределённых вариантах
по типу островного алгоритма [10; 11] не предлагалось использовать различные ГА.
В целом же было показано, что во многих случаях ГА действительно эффективно
ищут приближённое решение для SCS. Мы применили полученные нами ГА с ДРВ
для решения данной задачи и анализа использования различных ГО. При этом
из-за особенностей задачи коммивояжёра набор ГО был соответствующим образом
изменён.

2. Описание ГО для алгоритма разбиения файла
   на подстроки
2.1. Отличие рассматриваемых алгоритмов от классической схемы

   В наших ГА хромосома представляется не битовой строкой, как в классическом
алгоритме, а набором генов. На первом этапе для кодирования разбиения исход-
ного файла на подстроки один ген будет представлять собой большое целое число,
кодирующее положение разреза во входной последовательности (рассматриваемой
как последовательность байт). На втором этапе решения задачи поиска SCS мы сво-
дим её к задаче коммивояжёра, при этом каждая подстрока, полученная первым
алгоритмом, имеет номер в соответствии со своим положением в файле. Матрица
расстояний для вершин i и j, соответствующих подстрокам si и sj , содержит длину
префикса sj , являющегося суффиксом si . Для ЗК ген — это номер одной из вер-
шин графа маршрутов, а порядок генов определяет цепь, которая соединяет эти
вершины.
     Генетический алгоритм с динамическим распределением вероятностей выбора...      27

   Гены одной хромосомы мутируют с некоторой вероятностью независимо друг от
друга. В случае генерации разрезов гены непосредственно изменяют своё значение.
В случае ЗК гены меняют своё положение в хромосоме, что приводит к изменению
пути.
   При наследовании гены переходят в дочерние хромосомы целиком, кроссинго-
вер осуществляется по границам генов. Поскольку цель нашей работы — поиск
приближённого решения задачи построения кратчайшей суперстроки для произ-
вольных данных, далее мы сосредоточим внимание на разработанном нами алго-
ритме.
   Что касается решения ЗК, то нет единого мнения, какой из эвристических алго-
ритмов более эффективен для её решения, в большей части это зависит от качества
реализации того или иного варианта. Изначально предполагалось, что мы будем
пробовать совместить исходный алгоритм разбиения с различными вариантами ал-
горитма для решения ЗК.

2.2. Описание ГО для алгоритма разбиения файла на подстроки
   Для задач с целочисленным кодированием генов предусмотрены специальные
алгоритмы мутации и кроссинговера, немного отличающиеся от классических.
Предполагаем, что нашему ГА соответствуют параметры, определяющие макси-
мальное значение гена, которое по крайней мере определяется имеющимся вход-
ным файлом (обозначим это число chromosomeLenM ax), и максимальную длину
хромосом (обозначим geneAmountM ax). Предлагаются следующие мутации:
  1) случайное изменение одного из генов, реализуемое как генерация случайного
     целого числа n, имеющего равномерное распределение и не превышающего
     chromosomeLenM ax, которое не совпадало бы с уже имеющимися в списке
     генов хромосомы;
  2) прибавление или вычитание 1 (переход на соседнюю позицию) из текущего
     значения гена по модулю chromosomeLenM ax и проверка генов на совпаде-
     ние;
  3) прибавление к одному из генов случайного числа n, имеющего гауссово рас-
     пределение, по модулю chromosomeLenM ax и проверка генов на совпадение.
   Далее на базе этих функций были построены более агрессивные функции му-
тации, меняющие половину или произвольное число генов хромосомы, подвергаю-
щейся мутации.
   Число хромосом, которые подвергнутся мутации, устанавливается параметра-
ми запуска алгоритма, и поскольку наш алгоритм построен на основе ПГА, то это
значение не должно обычно превышать 1–5 % от общего числа хромосом в популя-
ции [1].
   Пример оператора мутации при использовании случайных чисел, имеющих гаус-
сово распределение:
      v o i d GaussianMutationN ( Chromosome chromosome , i n t n )
            {
                GaussianRandom gaussianRandom =
                                                   new GaussianRandom ( ) ;
                  i f ( n > chromosome . g e n e s . Count ( ) )
                        n = chromosome . g e n e s . Count ( ) ;
                        // gen p o s i t i o n s , where we ’ l l change v a l u e
                L i s t <i n t > p o s i t i o n s = new L i s t <i n t > ( ) ;
                int position ;
28                                    Ю. О. Кашкарева

                   p o s i t i o n = random . Next ( 0 , chromosome . g e n e s . Count ( ) ) ;
                    p o s i t i o n s . Add( p o s i t i o n ) ;
                    f o r ( i n t i = 0 ; i < n−1; i ++)
                    {
                   p o s i t i o n = random . Next ( 0 , chromosome . g e n e s . Count ( ) ) ;
                             w h i l e ( p o s i t i o n s . Contains ( p o s i t i o n ) )
                   p o s i t i o n = random . Next ( 0 , chromosome . g e n e s . Count ( ) ) ;
                              p o s i t i o n s . Add( p o s i t i o n ) ;
                    }
                    Gene newAmount ; // c r e a t e gene
                    f o r ( i n t i = 0 ; i < n ; i ++)
                    {
                   // i n t o gene c o n s t r u c t i o n v a l u e w i l l be taken i n
 newAmount = new Gene ( chromosome . g e n e s [ p o s i t i o n ] . iAmount
 + Convert . ToInt32 ( gaussianRandom . NextGaussian ( Gene . maxAmount/ 2 ,
             Gene . maxAmount / 6 ) ) ) ;
 // t h e r e must not be any d u p l i c a t e g e n e s i n chromosome
                             w h i l e ( chromosome . g e n e s . Contains ( newAmount ) )
   newAmount = new Gene ( chromosome . g e n e s [ p o s i t i o n ] . iAmount
             + Convert . ToInt32 ( gaussianRandom .
        NextGaussian ( Gene . maxAmount / 2 ,
                             Gene . maxAmount / 6 ) ) ) ;
    chromosome . g e n e s [ p o s i t i o n ] . iAmount = newAmount . iAmount ;
                    }
             }
             // g a u s s i a n mutation f o r some g e n e s
             v o i d GaussianMutationRandom ( Chromosome chromosome )
             {
                    i n t n = random . Next ( 0 , maxLength ) ;
                    GaussianMutationN ( chromosome , n ) ;
             }
   Дополнительно для нашего случая подходят мутации вставки и удаления генов.
При этом необходимо контролировать максимальное и минимальное число генов в
хромосоме, а при вставке, как указывалось выше, проверять наличие повторных
генов.
   Для нашего случая подходят такие операторы кроссинговера, которые, воз-
можно, изменяли бы число генов в хромосоме, однако не давали бы одному и тому
же гену появляться повторно. Были реализованы следующие операторы: одното-
чечный, многоточечный, универсальный кроссинговер, а также кроссинговер типа
Cut-and-Split. Первые три из указанных операторов сохраняют первоначальную
длину хромосом, последний позволяет склеивать куски хромосом произвольной
длины. При выполнении кроссинговера также необходимо проверять хромосомы
на корректность. Поскольку оператор Cut-and-Split менее известен и не относится
к классическим, приведём его код:
L i s t <Chromosome>
CutAndSplitCrossoverWithoutRef ( Chromosome parent1 ,
                                        Chromosome p a r e n t 2 )
            {
                L i s t <Chromosome> c h i l d s = new L i s t <Chromosome > ( ) ;
        Генетический алгоритм с динамическим распределением вероятностей выбора...                              29

                     c h i l d s . Add( new Chromosome ( ) ) ;
                     c h i l d s . Add( new Chromosome ( ) ) ;
                     i n t p o in t1 , p o i n t 2 ; // c r r o s s i g o v e r p o i n t s
                     p o i n t 1 = random . Next ( 0 , p a r e n t 1 . g e n e s . Count ) ;
                     p o i n t 2 = random . Next ( 0 , p a r e n t 2 . g e n e s . Count ) ;
// i t doesn ’ t f i t , i f l e n g t h i s b i g g e r then maximum o r i s 0
 w h i l e ( ( ( p o i n t 1 + p a r e n t 2 . g e n e s . Count − p o i n t 2 ) > maxLength )
       | | ( ( p o i n t 1 + p a r e n t 2 . g e n e s . Count − p o i n t 2 ) == 0 )
       | | ( ( p o i n t 2 + p a r e n t 1 . g e n e s . Count − p o i n t 1 ) > maxLength )
       | | ( ( p o i n t 2 + p a r e n t 1 . g e n e s . Count − p o i n t 1 ) ==0))
                     {
                             p o i n t 1 = random . Next ( 0 , p a r e n t 1 . g e n e s . Count ) ;
                             p o i n t 2 = random . Next ( 0 , p a r e n t 2 . g e n e s . Count ) ;
                     }
                     f o r ( i n t i = 0 ; i < p o i n t 1 ; i ++) // обмен частями
                     {
             i f ( ! ( c h i l d s [ 0 ] . g e n e s . Contains ( p a r e n t 1 . g e n e s [ i ] ) ) )
                                     c h i l d s [ 0 ] . g e n e s . Add( p a r e n t 1 . g e n e s [ i ] ) ;
                     }
                     f o r ( i n t i = 0 ; i < p o i n t 2 ; i ++)
                     {
             i f ( ! ( c h i l d s [ 1 ] . g e n e s . Contains ( p a r e n t 2 . g e n e s [ i ] ) ) )
                                     c h i l d s [ 1 ] . g e n e s . Add( p a r e n t 2 . g e n e s [ i ] ) ;
                     }
             f o r ( i n t i = p o i n t 2 ; i < p a r e n t 2 . g e n e s . Count ; i ++)
                     {
             i f ( ! ( c h i l d s [ 0 ] . g e n e s . Contains ( p a r e n t 2 . g e n e s [ i ] ) ) )
                                     c h i l d s [ 0 ] . g e n e s . Add( p a r e n t 2 . g e n e s [ i ] ) ;
                     }
             f o r ( i n t i = p o i n t 1 ; i < p a r e n t 1 . g e n e s . Count ; i ++)
                     {
             i f ( ! ( c h i l d s [ 1 ] . g e n e s . Contains ( p a r e n t 1 . g e n e s [ i ] ) ) )
                                     c h i l d s [ 1 ] . g e n e s . Add( p a r e n t 1 . g e n e s [ i ] ) ;
                     }
                     return childs ;
             }
    Для выбора родительской пары используются методы:
    • панмиксия — скрещивание случайных хромосом;
    • инбридинг — близкородственное скрещивание, под термином будем понимать
      хромосомы, имеющие схожее значение функции пригодности;
    • аутбридинг — скрещивание наиболее непохожих хромосом, под этим мы бу-
      дем понимать хромосомы с максимально отличающимся значением функции
      пригодности;
    • селекционное или элитарное скрещивание — скрещивание между собой луч-
      ших представителей.
  Для имбридинга и аутбридинга сначала сортируем популяцию по значению
функции пригодности, затем выполняем скрещивание в соответствии с получен-
ным порядком. Пример аутбридинга:
30                                             Ю. О. Кашкарева

      oid PairSelectionOutbriding ( delegate_Chrossover Chrossover )
              {
 // o u t b r e e d i n g , f i r s t i s taken randomly , second−t he most c l o s e
  L i s t <I R o u l l e t W h e e l S e c t o r >
  c o l l e c t i o n = new L i s t <I R o u l l e t W h e e l S e c t o r > ( ) ;
                     f o r e a c h ( Chromosome chromosome i n c u r r e n t G e n e r a t i o n )
                       { c o l l e c t i o n . Add( chromosome ) ;
                       }
          RoulletWheel r o u l l e t W h e e l = new RoulletWheel ( c o l l e c t i o n ) ;
                 i n t first_parent_num ;
                     first_parent_num = r o u l l e t W h e e l . Spin ( ) ;
                   p a r e n t s . Add( c u r r e n t G e n e r a t i o n [ first_parent_num ] ) ;
            i n t f i t n e s s _ d i f f e r e n s e ; // d i f f e r e n c e between f i t n e s e s
                   i n t second_parent_num ; // parent ’ s number
                second_parent_num = first_parent_num ;
              fitness_differense = 0;

                        f o r ( i n t i = 0 ; i < c u r r e n t G e n e r a t i o n . Count ; i ++)
                        {
     i f ( ( i != first_parent_num )
           && ( Abs ( c u r r e n t G e n e r a t i o n [ i ] . f i t n e s s _
                − c u r r e n t G e n e r a t i o n [ first_parent_num ] . f i t n e s s _ )
                                                                     > fitness_differense ))
        {
          f i t n e s s _ d i f f e r e n s e = Abs ( c u r r e n t G e n e r a t i o n [ i ] . f i t n e s s _
                − c u r r e n t G e n e r a t i o n [ first_parent_num ] . f i t n e s s _ ) ;
                                  second_parent_num = i ;
                                }
                        }
                  p a r e n t s . Add( c u r r e n t G e n e r a t i o n [ second_parent_num ] ) ;
                        c h i l d s = Chrossover ( parents [ 0 ] , parents [ 1 ] ) ;
                }

   В качестве оператора отбора нам подойдёт любой из известных, например про-
центный элитарный, рулеточный или ранговый, а также случайный на основе рав-
ной вероятности хромосом выжить или умереть.
   Чтобы избежать потери перспективных хромосом, можно использовать про-
центный элитарный отбор.
   Необходимо обратить внимание на то, что не любая произвольная комбинация
ГО позволит получить хороший ГА. В некоторых случаях, например при сочетании
случайного формирования родительских пар и случайного отбора, нет никакой га-
рантии роста значения функции пригодности и схождения алгоритма. Более того,
мы можем утратить хорошие решения, поэтому требуется дополнительно прове-
рить работоспособность алгоритма.
   Алгоритм предполагает, что можно использовать различные функции пригод-
ности, которые соответствовали бы определённому шаблону. Были реализованы
функция пригодности на основе решения задачи о назначении и функция при-
годности на основе суммирования элементов матрицы, описывающей пересечения
строк полученного разбиения, что даёт более грубую, но и более быструю оценку
полученного разбиения.
     Генетический алгоритм с динамическим распределением вероятностей выбора...   31

2.3. Формирование начальной популяции для алгоритма разбиения
     файла на подстроки
   Если нам известно что-то о структуре входных данных, то мы можем пред-
положить, как именно можно будет эффективно разбить файл для дальнейшего
сжатия, в частности какой длины должны быть подстроки для сжатия.
   Однако в общем случае мы не можем заранее сделать однозначный вывод о
том, в каких позициях лучше разбить файл, чтобы получить наиболее короткую
суперстроку. Мы решили генерировать начальную популяцию полностью случай-
ным образом.
   Также алгоритму необходимо передать параметры, задающие максимальное
значение гена, которое по крайней мере определяется имеющимся входным фай-
лом (обозначим это число chromosomeLenM ax), и максимальную длину хромосом
(обозначим geneAmountM ax). Начальный размер популяции также будет в нашем
случае входным параметром алгоритма, обозначим его populationSize.
   Корректный выбор параметров алгоритма представляет собой отдельную и до-
статочно сложную задачу. При этом в простейшем случае предъявляется требо-
вание о том, что любое допустимое решение должно быть получено с ненулевой
вероятностью в ходе работы ГА.
   Опишем непосредственно алгоритм генерации начальной популяции. Для каж-
дой новой хромосомы выполняются следующие два действия:
  1) генерируется длина хромосомы n ≤ chromosomeLenM ax; длины хромосом
     выбираются в соответствии с равномерным распределением;
  2) генерируется n генов в виде целых чисел, характеризующих позицию разре-
     зов исходного файла; эти числа также выбираются с помощью равномерного
     распределения.
   В зависимости от алгоритма размер популяции в дальнейшем может меняться
или сохраняться. Также текущее поколение может полностью замещаться новым,
полностью сохраняться или частично сохраняться.

3. Описание двух реализаций ГА с ДРВ
   На основе работ [2] и [4] нами предлагаются две собственные интерпретации ГА
с ДРВ.

3.1. ГА с фиксированием использованного набора ГО
   В ходе выполнения ГА на каждом шаге в поколение будет добавляться ровно
одна новая хромосома, которая заменит худшую хромосому из старого поколения.
Таким образом, размер поколения всегда будет равен populationSize. Для каж-
дой хромосомы будет фиксироваться, каким набором генетических операторов она
получена. Вероятность применения того или иного генетического оператора будет
зависеть от числа особей в текущей популяции, полученных с помощью этого опе-
ратора. Количество итераций numberOf Iterations алгоритма будет изменяемым
параметром, сообщаемым при старте алгоритма. Мутация каждого потомка про-
исходит с вероятностью mutationP robability, которая также является задаваемым
параметром.
   Для каждого поколения ГА конкретный набор ГО формируется по алгорит-
му рулетки на основе вычисленных вероятностных характеристик каждого опера-
тора. При инициализации алгоритма для каждого типа ГО формируется группа
32                                Ю. О. Кашкарева

функций, реализующих его. Для каждой функции в своей группе задаётся веро-
ятность её применения. Распределение вероятностей первоначально равномерное.
В каждой хромосоме, полученной в данной итерации, фиксируется тройка операто-
ров данной итерации. Прежде чем накопить статистику об использовании ГО, мы
должны проделать некоторое количество итераций алгоритма, обозначим это чис-
ло за numberOf IterationsF irstReinitialize. Далее распределение вероятности опе-
раторов будет корректироваться каждые numberOf IterationsReinitialize шагов.
Вероятность использования каждого ГО вычисляется как отношение числа живых
хромосом в популяции, полученной с помощью данного ГО, к общему числу хромо-
сом, для которых определены ГО, с помощью которых они получены. Хромосомы,
оставшиеся от инициализации популяции, исключаются из рассмотрения.
   Сами ГО выбираются следующим образом :
     1. При инициализации алгоритма для каждого типа операторов — S, C, M —
        формируется группа функций, реализующих различные виды группирова-
        ния в пары, кроссинговера и мутации соответственно. Далее рассматриваем
        P arentP airs, Chrossover, M utation как коллекцию соответствующих функ-
        ций.
     2. Для каждого оператора в своей группе вычислена его вероятность примене-
        ния. В начальный момент времени вероятности для всех операторов в группе
        равны.
     3. На каждом шаге ГА конкретный набор из трёх операторов формируется с
        помощью алгоритма рулетки. В каждой хромосоме, полученной в данной ите-
        рации, фиксируется тройка операторов.
     4. Прежде чем накопить статистику об использовании ГО, мы должны про-
        делать некоторое количество итераций алгоритма, обозначим это число за
        numberOf IterationsAshkyeReinitialize. Далее частоты будут пересчитывать-
        ся каждые numberOf IterationsReinitialize шагов.
     5. Мы установим вероятность использования каждого ГО как отношение числа
        живых хромосом в популяции, полученной с помощью данного ГО, к общему
        числу хромосом, для которых определены ГО, с помощью которых они полу-
        чены, то есть на число хромосом, полученных в ходе выполнения итераций
        ГА, а не сохранившихся из начальной популяции.
    Возможны различные модификации алгоритма. Например, популяция может
иметь нефиксированный размер. В этом случае к популяции можно добавлять всех
полученных потомков либо потомков, прошедших оценку функцией пригодности
(сама функция пригодности может выбираться аналогично другим генетическим
операторам). Минус такого подхода — размер популяции наиболее существенно ска-
зывается на времени выполнения. В популяцию можно попытаться добавить всех
полученных потомков, пригодность которых больше, чем пригодность худших осо-
бей в популяции. Кроме того, можно определить критерий сходимости популяции
следующим образом: если в течение N итераций полученные потомки имеют худ-
шую (или не лучшую) приспособленность, чем особи в популяции, то можно счи-
тать, что популяция сошлась. В качестве ответа можно вернуть лучшую особь в
текущей популяции. Плюс такого подхода — на каждой итерации нам надо пересчи-
тать функцию пригодности только для полученных потомков children. Также если
популяция отсортирована, то новые элементы легко добавить. Минусы по сравне-
нию со следующим подходом — в каждой итерации генерируется меньше элементов,
и, соответственно, необходимо увеличивать число итераций.
     Генетический алгоритм с динамическим распределением вероятностей выбора...   33




               ГА с ДРВ с оценкой ГО по среднему значению пригодности

3.2. ГА с ДРВ с оценкой ГО по среднему значению пригодности

    В ходе выполнения ГА на каждой итерации генерируется некоторое количество
новых хромосом. Старое поколение будет полностью заменено новым поколением,
сформированным из числа лучших хромосом, полученных на этой итерации. Для
регулирования численности будет применяться оператор рекомбинации. При этом
размер полученного поколения всегда будет populationSize. Если на данном этапе
было получено меньше новых хромосом, чем populationSize, то лучшие хромосомы
из детей войдут в новое поколение несколько раз. Схема алгоритма представлена на
рисунке. Определение числа итераций и мутация потомков происходят аналогично
описанному в разд. 3.1 алгоритму.
    Аналогично предыдущему алгоритму при инициализации для каждого типа
операторов формируется группа функций, реализующих соответствующие ГО : от-
бор родительских хромосом, выбор родительской пары, кроссинговер, мутация, ре-
комбинация. В начальный момент времени вероятности для всех операторов в груп-
пе задаются равными. На каждом шаге ГА конкретный набор из пяти операторов
формируется с помощью алгоритма рулетки.
   C каждой из групп функций связывается два счётчика, один из которых пока-
зывает число хромосом, задействованных для данного оператора в текущем поко-
34                                       Ю. О. Кашкарева

лении, а второй — число полученных прогрессивных хромосом, то есть хромосом,
для которых значение функции пригодности выше, чем среднее значение функ-
ции пригодности в родительской популяции. После выполнения каждого опера-
тора фиксируем количество прогрессивных хромосом в популяции и общее число
хромосом, сгенерированных алгоритмом. На основании этих частот пересчитыва-
ем вероятность выбора соответствующего генетического оператора как отношение
количества полученных этим оператором прогрессивных хромосом к общему коли-
честву прогрессивных хромосом.
   При реализации алгоритма в таком виде (даже без оценки пригодности и пе-
ресчёта вероятности использования ГА) в проведённых нами тестах наблюдается
существенный рост времени работы алгоритма в сравнении с аналогичными де-
терминированными аналогами. Наиболее трудозатратными оказались операции по
пересчёту значений функции пригодности для всей популяции и сортировка попу-
ляции по значению функции пригодности. Вследствие этого значительное время
занимает вычисление оператора редукции в соответствии со значением функции
пригодности. Этот оператор требует значительно больше времени на выполнение в
сравнении с другими операторами. Однако это единственный оператор редукции,
который гарантированно позволяет увеличивать значение функции пригодности в
новой популяции. Без этого оператора некоторые варианты сочетания селекции,
кроссинговера и мутации будут носить абсолютно случайный характер. Таким об-
разом, данный алгоритм требует оптимизации по времени, а также очень сложен
для статистического анализа, так как многие величины в ходе выполнения алго-
ритма будут случайными, при этом разные генетические операторы будут менять
эти величины по-разному (размер пула родителей и число потомков, в частности).

Список литературы
     1. Гладков, Л. А. Генетические алгоритмы / Л. А. Гладков, В. В. Курейчик, В. М. Ку-
        рейчик. — М. : Физматлит, 2006. — 320 с.
     2. Бюргер, Ю. А. Мягкие вычисления [Электронный ресурс] / Ю. А. Бюргер. — URL:
        http://www.getinfo.ru/article28_3.html (дата обращения: 20.03.2016).
     3. Петров, Ю. Ю. Применение генетического алгоритма с регуляцией вероятностей
        генетических операторов при решении задачи упаковки в контейнеры / Ю. Ю. Пет-
        ров // Сб. науч. тр. Сев.-Кавказ. гос. тех. ун-та. Сер. естественнонауч. — 2006. —
        № 2.
     4. Мясников, А. С. Островной генетический алгоритм с динамическим распре-
        делением вероятностей выбора генетических операторов [Электронный ресурс] /
        А. С. Мясников. — URL: http://technomag.edu.ru/doc/136503.html (дата обращения:
        27.05.2012).
     5. Gallant, J. On finding minimal length superstrings / J. Gallant, D. Maier, J. A. Storer //
        J. of Computer and System Sciences. — 1980. — Vol. 20, no. 1. — P. 50–58.
     6. Linear approximation of shortest superstring / A. Blum [et al.] // J. of the ACM. —
        1994. — Vol. 4, iss. 4. — P. 630–647.
     7. Kohn, S. A generating function approach to the traveling salesman problem / S. Kohn,
        A. Gottlieb, M. Kohn // Proceedings of the 1977 annual conference ACM ’77. — New
        York, 1977. — P. 294–300.
     8. An algorithm for the traveling salesman problem / J. D. C. Little [et al.] // Operations
        Research. — 1963. — Vol. 11, iss. 6. — P. 972–989.
     9. Sweedyk, Z. A 2.5-approximation algorithm for shortest superstring / Z. Sweedyk //
        SIAM J. of Computing. — 1999. — Vol. 29, no. 3. — P. 954–986.
       Генетический алгоритм с динамическим распределением вероятностей выбора...                 35

 10. Liu, X. Algorithms for the shortest common superstring problem / X. Liu, O. Sykora //
     Parallel Numerics ’05: Theory and Application / ed. by M. Vajteršic [et al.]. — Ljubljana ;
     Salzburg : Jošef Stefan Inst. : Univ. of Salzburg, 2005. — P. 97–107.
 11. Zaritsky, A. Coevolving solution to the shortest common superstring problem /
     A. Zaritsky, M. Sipper // BioSystems. — 2004. — Vol. 76, no. 1. — P. 209–216.
Поступила в редакцию 28.04.2016
После переработки 07.06.2016

                                     Сведения об авторе
Кашкарева Юлия Олеговна, аспирантка математического факультета, Челябинский
государственный университет, Челябинск, Россия; e-mail: kashkareva.julija@gmail.com.



Chelyabinsk Physical and Mathematical Journal. 2016. Vol. 1, iss. 2. P. 24–36.

GENETIC ALGORITHM WITH A DYNAMIC PROBABILITIES
DISTRIBUTION OF THE SELECTION OF GENETIC OPERATORS
FOR SOLVING OF PROBLEMS WITH INTEGER GENES CODING
Yu.O. Kashkareva
Chelyabinsk State University, Chelyabinsk, Russia
kashkareva.julija@gmail.com

      Two genetic algorithms are designed and tested for constructing of the superstring for an
      arbitrary binary file. They are based on the adaptive choosing of genetic operators set.

      Keywords: superstring construction, genetic algorithm, travelling salesman problem.

References
   1. Gladkov L.A., Kureychik V.V., Kureychik V.M. Geneticheskiye algoritmy
      [Genetic algorithms]. Moscow, Fizmatlit Publ., 2006. 320 p. (In Russ.).
   2. Byurger       Yu.А. Myagkiye vychisleniya [Soft computing]. Available at:
      http://www.getinfo.ru/article28_3.html, accepted 20.03.2016. (In Russ.).
   3. Petrov Yu.Yu. Primenenie geneticheskogo algoritma s regulyatsiey veroyatnostey
      geneticheskikh operatorov pri reshenii zadachi upakovki v konteinery [Application of
      genetic algorithm to the regulation of the probability of genetic operators in solving of the
      bin packing problem]. Sbornik nauchnykh trudov Severo-Kavkazskogo gosudarstvennogo
      tekhnicheskogo universiteta. Seriya Yestestvennonauchnaya [Proceedings of North
      Caucasus State Technical University. Nature Sciences Series], 2006, no. 2. (In Russ.).
   4. Myasnikov A.S. Ostrovnoy geneticheskiy algoritm s dinamicheskim raspredeleniyem
      veroyatnostey      vybora     geneticheskikh operatorov    [Island algorithm    with
      dynamic probabilities distribution of genetic operators choosing]. Available at:
      http://technomag.edu.ru/doc/136503.html, accepted 27.05.2012. (In Russ.).
   5. Gallant J., Maier D., Storer J.A. On finding minimal length superstrings. Journal
      of Computer and System Sciences, 1980, vol. 20, no. 1, pp. 50–58.
   6. Blum A. [et al.]. Linear approximation of shortest superstring. Journal of the ACM,
      1994, vol. 41, iss. 4, pp. 630–647.
   7. Kohn S., Gottlieb A., Kohn M. A generating function approach to the traveling
      salesman problem. Proceedings of the 1977 annual conference ACM ’77. New York, 1977.
      Pp. 294–300.
36                                     Ю. О. Кашкарева

   8. Little J.D.C. [et al.]. An algorithm for the traveling salesman problem. Operations
      Research, 1963, vol. 11, iss. 6, pp. 972–989.
   9. Sweedyk Z. A 2.5-approximation algorithm for shortest superstring. SIAM Journal of
      Computing, 1999, vol. 29, no. 3, pp. 954–986.
  10. Liu X., Sykora O. Algorithms for the shortest common superstring problem. Parallel
      Numerics ’05: Theory and Application, ed. by M. Vajteršic [et al.]. Ljubljana, Jošef
      Stefan Institute; Salzburg, University of Salzburg, 2005. Pp. 97–107.
  11. Zaritsky A., Sipper M. Coevolving solution to the shortest common superstring
      problem. BioSystems, 2004, vol. 76, no. 1, pp. 209–216.

Accepted article received 28.04.2016
Corrections received 07.06.2016
